{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad222b4d",
   "metadata": {},
   "source": [
    "## 将txt转换为xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a16c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xinlong\\AppData\\Local\\Temp\\ipykernel_6820\\2552544644.py:23: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  my_excel.to_excel(outdir, index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def txt2excel(fname):\n",
    "    fdir = \"./data/\" + fname + \".txt\"\n",
    "    my_data_dict = {}\n",
    "    f = open(fdir, \"r\", encoding=\"utf-8\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        str = \"\"\n",
    "        for word in line:\n",
    "            if word.__eq__(line[0]):  # 去掉首个单词的空格\n",
    "                str = word\n",
    "            else:\n",
    "                str += ' ' + word\n",
    "        my_data_dict[str] = 1\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    my_excel = pandas.DataFrame({\"comment\": list(my_data_dict.keys())})\n",
    "    outdir = \"./data/\" + fname + \".xls\"\n",
    "    my_excel.to_excel(outdir, index=False)\n",
    "\n",
    "    print(\"done!\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    txt2excel(\"pos\")\n",
    "    txt2excel(\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95536def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     with open(\"./data/pos.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "#       first_line = f.readline()\n",
    "#       # This would create columns as per your text file\n",
    "#       df = pd.DataFrame(columns = first_line.split(\"\\t\")) # assuming your entire data is tab seperated\n",
    "#       counter = 0\n",
    "#       for line in f.readlines(): # iterating over remaining data\n",
    "#         df.loc[counter] = line.split(\"\\t\")\n",
    "#         counter+= 1\n",
    "#       df.to_excel(\"your output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open(\"./data/pos.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "        df = pd.DataFrame(columns=[\"comment\"])\n",
    "        counter = 0\n",
    "        for line in f.readlines(): # iterating over remaining data\n",
    "            df.loc[counter] = line.split(\"\\t\")\n",
    "            counter += 1\n",
    "        df.to_excel(\"your output2.xlsx\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b8025ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba as jb\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fed735cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Xinlong\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.858 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "neg =pd.read_excel(\"data/neg.xls\",header=None, index_col=None)\n",
    "pos =pd.read_excel(\"data/pos.xls\",header=None, index_col=None)\n",
    "# 这是两类数据都是x值\n",
    "pos['comment'] = pos[0].apply(lambda x:list(jb.cut(x)))\n",
    "neg['comment'] = neg[0].apply(lambda x:list(jb.cut(x)))\n",
    "#需要y值  0 代表neg 1代表是pos\n",
    "y = np.concatenate((np.ones(len(pos)),np.zeros(len(neg))))\n",
    "X = np.concatenate((pos['comment'],neg['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b704ec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "#保存数据\n",
    "np.save(\"data/y_train.npy\", y_train)\n",
    "np.save(\"data/y_test.npy\", y_test)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef493bce",
   "metadata": {},
   "source": [
    "## 对句子中的所有词向量取均值，来生成一个句子的vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b3b6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector(text, size, wv):\n",
    "    #创建一个指定大小的数据空间\n",
    "    vec = np.zeros(size).reshape((1,size))\n",
    "    #count是统计有多少词向量\n",
    "    count = 0\n",
    "    #循环所有的词向量进行求和\n",
    "    for w in text:\n",
    "        try:\n",
    "            vec +=  wv[w].reshape((1,size))\n",
    "            count +=1\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    #循环完成后求均值\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8604f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化模型和词表\n",
    "wv = Word2Vec(vector_size=300,min_count=10)\n",
    "wv.build_vocab(X_train)\n",
    "# 训练并建模\n",
    "wv.train(X_train, total_examples=1, epochs=1)\n",
    "#获取train_vecs\n",
    "train_vecs = np.concatenate([build_vector(z,300,wv) for z in X_train])\n",
    "#保存处理后的词向量\n",
    "np.save('data/train_vecs.npy',train_vecs)\n",
    "#保存模型\n",
    "wv.save(\"data/model3.pkl\")\n",
    "\n",
    "wv.train(X_test,total_examples=1, epochs=1)\n",
    "test_vecs = np.concatenate([build_vector(z,300,wv) for z in X_test])\n",
    "np.save('data/test_vecs.npy',test_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265dab3a",
   "metadata": {},
   "source": [
    "## 训练SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1478aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.5335463258785943\n"
     ]
    }
   ],
   "source": [
    "#创建SVC模型\n",
    "cls = SVC(kernel=\"rbf\",verbose=True)\n",
    "#训练模型\n",
    "cls.fit(train_vecs,y_train)\n",
    "#保存模型\n",
    "joblib.dump(cls,\"data/svcmodel.pkl\")\n",
    "#输出评分\n",
    "print(cls.score(test_vecs,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dec501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反感\n",
      "反感\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import numpy as np\n",
    "import jieba as jb\n",
    "import joblib\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class core():\n",
    "    def __init__(self,str):\n",
    "        self.string=str\n",
    "\n",
    "        \n",
    "    def build_vector(self,text,size,wv):\n",
    "        #创建一个指定大小的数据空间\n",
    "        vec = np.zeros(size).reshape((1,size))\n",
    "        #count是统计有多少词向量\n",
    "        count = 0\n",
    "        #循环所有的词向量进行求和\n",
    "        for w in text:\n",
    "            try:\n",
    "                vec +=  wv[w].reshape((1,size))\n",
    "                count +=1\n",
    "            except:\n",
    "                continue\n",
    "        #循环完成后求均值\n",
    "        if count!=0:\n",
    "            vec/=count\n",
    "        return vec\n",
    "    \n",
    "    \n",
    "    def get_predict_vecs(self,words):\n",
    "        # 加载模型\n",
    "        wv = Word2Vec.load(\"data/model3.pkl\")\n",
    "        #将新的词转换为向量\n",
    "        train_vecs = self.build_vector(words,300,wv)\n",
    "        return train_vecs\n",
    "    \n",
    "    \n",
    "    def svm_predict(self,string):\n",
    "        # 对语句进行分词\n",
    "        words = jb.cut(string)\n",
    "        # 将分词结果转换为词向量\n",
    "        word_vecs = self.get_predict_vecs(words)\n",
    "        #加载模型\n",
    "        cls = joblib.load(\"data/svcmodel.pkl\")\n",
    "        #预测得到结果\n",
    "        result = cls.predict(word_vecs)\n",
    "        #输出结果\n",
    "        if result[0]==1:\n",
    "            return \"好感\"\n",
    "        else:\n",
    "            return \"反感\"\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        s=self.svm_predict(self.string)\n",
    "        return s\n",
    "\n",
    "root=Tk()\n",
    "root.title(\"情感分析\")\n",
    "sw = root.winfo_screenwidth()\n",
    "#得到屏幕宽度\n",
    "sh = root.winfo_screenheight()\n",
    "#得到屏幕高度\n",
    "ww = 500\n",
    "wh = 300\n",
    "x = (sw-ww) / 2\n",
    "y = (sh-wh) / 2-50\n",
    "root.geometry(\"%dx%d+%d+%d\" %(ww,wh,x,y))\n",
    "# root.iconbitmap('tb.ico')\n",
    "\n",
    "lb2=Label(root,text=\"输入内容，按回车键分析\")\n",
    "lb2.place(relx=0, rely=0.05)\n",
    "\n",
    "txt = Text(root,font=(\"宋体\",20))\n",
    "txt.place(rely=0.7, relheight=0.3,relwidth=1)\n",
    "\n",
    "inp1 = Text(root, height=15, width=65,font=(\"宋体\",18))\n",
    "inp1.place(relx=0, rely=0.2, relwidth=1, relheight=0.4)\n",
    "\n",
    "def run1():\n",
    "    txt.delete(\"0.0\",END)\n",
    "    a = inp1.get('0.0',(END))\n",
    "    p=core(a)\n",
    "    s=p.main()\n",
    "    print(s)\n",
    "    txt.insert(END, s)   # 追加显示运算结果\n",
    "\n",
    "def button1(event):\n",
    "    btn1 = Button(root, text='分析', font=(\"\",12),command=run1) #鼠标响应\n",
    "    btn1.place(relx=0.35, rely=0.6, relwidth=0.15, relheight=0.1)\n",
    "    # inp1.bind(\"<Return>\",run2) #键盘响应\n",
    "\n",
    "button1(1)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd55f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design39",
   "language": "python",
   "name": "design39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
